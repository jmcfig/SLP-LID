{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656db13c",
   "metadata": {},
   "source": [
    "# GlotLID and MaskLID Experiments\n",
    "\n",
    "This notebook sets up GlotLID for sentence-level LID and runs MaskLID for code-switching on a small sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3945a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Environment setup: install required packages\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    print(f\"Installing {pkg}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# Install huggingface_hub and numpy if missing\n",
    "try:\n",
    "    import huggingface_hub  # noqa: F401\n",
    "except Exception:\n",
    "    pip_install(\"huggingface_hub\")\n",
    "\n",
    "try:\n",
    "    import numpy as np  # noqa: F401\n",
    "except Exception:\n",
    "    pip_install(\"numpy\")\n",
    "\n",
    "# Install fasttext (Windows-friendly): prefer fasttext-numpy2-wheel, else fallback to fasttext\n",
    "fasttext = None\n",
    "try:\n",
    "    import fasttext  # type: ignore\n",
    "except Exception:\n",
    "    try:\n",
    "        pip_install(\"fasttext-numpy2-wheel\")\n",
    "        import fasttext  # type: ignore  # noqa: E402\n",
    "    except Exception:\n",
    "        pip_install(\"fasttext\")\n",
    "        import fasttext  # type: ignore  # noqa: E402\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912c7818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmigu\\anaconda3\\envs\\glotlid310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: C:\\Users\\jmigu\\.cache\\huggingface\\hub\\models--cis-lmu--glotlid\\snapshots\\74cb50b709c9eefe0f790030c6c95c461b4e3b77\\model.bin\n",
      "Loaded GlotLID with 2102 labels\n",
      "(('__label__eng_Latn', '__label__isl_Latn', '__label__deu_Latn'), array([9.9636394e-01, 2.0239984e-03, 5.2679953e-04], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Download and load GlotLID model\n",
    "from huggingface_hub import hf_hub_download\n",
    "import fasttext\n",
    "import numpy as np\n",
    "\n",
    "# Download latest model (v3 as of README); you can pin to model_v3.bin\n",
    "model_path = hf_hub_download(repo_id=\"cis-lmu/glotlid\", filename=\"model.bin\", cache_dir=None)\n",
    "print(\"Model path:\", model_path)\n",
    "\n",
    "# Load the model\n",
    "model = fasttext.load_model(model_path)\n",
    "print(\"Loaded GlotLID with\", len(model.labels), \"labels\")\n",
    "\n",
    "# Custom predict using output_matrix + softmax (avoids numpy 2.x issue in fasttext.predict)\n",
    "labels = model.get_labels()\n",
    "output_matrix = model.get_output_matrix()\n",
    "\n",
    "def _softmax(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(x)\n",
    "    e = np.exp(x - np.max(x))\n",
    "    return e / e.sum()\n",
    "\n",
    "def glotlid_predict(text: str, k: int = 3):\n",
    "    sv = model.get_sentence_vector(text)\n",
    "    logits = np.dot(output_matrix, sv)\n",
    "    probs = _softmax(logits)\n",
    "    top_idx = np.argsort(probs)[-k:][::-1]\n",
    "    top_labels = tuple(labels[i] for i in top_idx)\n",
    "    top_probs = probs[top_idx]\n",
    "    return top_labels, top_probs\n",
    "\n",
    "# Quick sanity check\n",
    "print(glotlid_predict(\"Hello, world!\", k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d204c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Hello, how are you?\n",
      "PRED: ('__label__eng_Latn', '__label__ind_Latn', '__label__sna_Latn') [0.9999676942825317, 3.187024049111642e-05, 2.1771765545963717e-07]\n",
      "-\n",
      "TEXT: ¿Cómo estás? Todo bien.\n",
      "PRED: ('__label__spa_Latn', '__label__glg_Latn', '__label__gug_Latn') [0.9999990463256836, 7.620928954565898e-07, 1.3862313608115073e-07]\n",
      "-\n",
      "TEXT: Merhaba, nasılsın?\n",
      "PRED: ('__label__tur_Latn', '__label__azj_Latn', '__label__diq_Latn') [0.9999998807907104, 1.2680378347340593e-07, 4.7710493333852355e-08]\n",
      "-\n",
      "TEXT: C'est une belle journée.\n",
      "PRED: ('__label__fra_Latn', '__label__oci_Latn', '__label__fro_Latn') [1.0, 1.8759225284270542e-08, 1.1848276137982339e-08]\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Helper: GlotLID predictions on a small dataset\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def predict_topk(texts: List[str], k: int = 3) -> List[Tuple[tuple, list]]:\n",
    "    results = []\n",
    "    for t in texts:\n",
    "        labels_, probs_ = glotlid_predict(t, k)\n",
    "        results.append((labels_, probs_.tolist()))\n",
    "    return results\n",
    "\n",
    "examples = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"¿Cómo estás? Todo bien.\",\n",
    "    \"Merhaba, nasılsın?\",\n",
    "    \"C'est une belle journée.\",\n",
    "]\n",
    "\n",
    "glotlid_results = predict_topk(examples, k=3)\n",
    "for text, (labels_, probs_) in zip(examples, glotlid_results):\n",
    "    print(\"TEXT:\", text)\n",
    "    print(\"PRED:\", labels_, probs_)\n",
    "    print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c74d51f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__tur_Latn: 0.9994\n",
      "__label__azj_Latn: 0.0003\n",
      "__label__kiu_Latn: 0.0001\n",
      "__label__gag_Latn: 0.0001\n",
      "__label__crh_Latn: 0.0001\n",
      "__label__kaa_Latn: 0.0000\n",
      "__label__diq_Latn: 0.0000\n",
      "__label__tuk_Latn: 0.0000\n",
      "__label__tat_Latn: 0.0000\n",
      "__label__uig_Latn: 0.0000\n",
      "__label__kmr_Latn: 0.0000\n",
      "__label__dgr_Latn: 0.0000\n",
      "__label__kas_Latn: 0.0000\n",
      "__label__rhg_Latn: 0.0000\n",
      "__label__daa_Latn: 0.0000\n"
     ]
    }
   ],
   "source": [
    "def show_top_k(text: str, k: int = 3):\n",
    "    labels_, probs_ = glotlid_predict(text, k)\n",
    "    for label, prob in zip(labels_, probs_):\n",
    "        print(f\"{label}: {prob:.4f}\")\n",
    "\n",
    "example_text = \"bir kahve dükkanında geçen film tadında güzel bir şarkıya ayrılsın gece falling in love at a coffee shop\"\n",
    "\n",
    "show_top_k(example_text, k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code-switch text:\n",
      " bir kahve dükkanında geçen film tadında güzel bir şarkıya ayrılsın gece falling in love at a coffee shop\n",
      "MaskLID segments:\n",
      "__label__tur_Latn : bir kahve dükkanında geçen tadında güzel bir şarkıya ayrılsın gece\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MaskLID' object has no attribute 'get_unassigned_segments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(lang, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, seg)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# show the remaining unassigned segments\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m unassigned \u001b[38;5;241m=\u001b[39m \u001b[43mmasklid_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_unassigned_segments\u001b[49m(cs_text, ans)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnassigned segments:\u001b[39m\u001b[38;5;124m\"\u001b[39m, unassigned)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MaskLID' object has no attribute 'get_unassigned_segments'"
     ]
    }
   ],
   "source": [
    "# MaskLID: Code-switching experiments\n",
    "# Import MaskLID from local repo folder\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path.cwd()\n",
    "sys.path.insert(0, str(root / \"MaskLID\"))\n",
    "from masklid import MaskLID  # noqa: E402\n",
    "\n",
    "# Reuse GlotLID model file\n",
    "masklid_model = MaskLID(str(model_path), languages=-1)\n",
    "\n",
    "# Pick the code-switching example (last one from examples)\n",
    "cs_text = example_text\n",
    "print(\"Code-switch text:\\n\", cs_text)\n",
    "\n",
    "ans = masklid_model.predict_codeswitch(\n",
    "    cs_text,\n",
    "    beta=20,\n",
    "    alpha=3,\n",
    "    max_lambda=3,\n",
    "    min_length=10,\n",
    "    min_prob=0.90,\n",
    "    max_retry=3,\n",
    "    alpha_step_increase=3,\n",
    "    beta_step_increase=5,\n",
    ")\n",
    "print(\"MaskLID segments:\")\n",
    "for lang, seg in ans.items():\n",
    "    print(lang, \":\", seg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd04619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set dataset_path to your CSV to run batch predictions.\n"
     ]
    }
   ],
   "source": [
    "# Optional: Load your own CSV dataset\n",
    "# Expects a CSV with a text column. Adjust path/column as needed.\n",
    "import sys, subprocess\n",
    "\n",
    "def ensure(pkg: str):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except Exception:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "ensure(\"pandas\")\n",
    "import pandas as pd\n",
    "\n",
    "# Configure your dataset path and text column\n",
    "# Example: dataset_path = r\"C:\\\\Users\\\\<you>\\\\Desktop\\\\mydata.csv\"\n",
    "dataset_path = r\"\"\n",
    "text_column = \"text\"\n",
    "\n",
    "if dataset_path:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    texts = df[text_column].dropna().astype(str).tolist()[:50]\n",
    "    print(f\"Loaded {len(texts)} texts from {dataset_path}\")\n",
    "    preds = predict_topk(texts, k=3)\n",
    "    for t, (labels, probs) in zip(texts[:5], preds[:5]):\n",
    "        print(\"TEXT:\", t[:120].replace(\"\\n\", \" \") + (\"...\" if len(t) > 120 else \"\"))\n",
    "        print(\"PRED:\", labels, probs)\n",
    "        print(\"-\")\n",
    "else:\n",
    "    print(\"Set dataset_path to your CSV to run batch predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0dc172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glotlid310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
